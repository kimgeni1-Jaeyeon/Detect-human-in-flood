{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import RMSprop ##\n",
    "from keras.preprocessing.image import ImageDataGenerator ##\n",
    "from shutil import copyfile\n",
    "from os import getcwd\n",
    "from os import listdir\n",
    "import cv2\n",
    "from tensorflow.python.keras.layers import Conv2D, Input, ZeroPadding2D, Activation, MaxPooling2D, Flatten, Dense ##BatchNormalization\n",
    "from tensorflow.python.keras.models import Model, load_model ##\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint ##\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import imutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image  as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    dataset = []\n",
    "    \n",
    "    for dataimage in os.listdir(SOURCE):\n",
    "        data = SOURCE + dataimage\n",
    "        if(os.path.getsize(data) > 0):\n",
    "            dataset.append(dataimage)\n",
    "        else:\n",
    "            print('Skipped ' + dataimage)\n",
    "            print('There is no file.')\n",
    "    \n",
    "    train_len = int(len(dataset) * SPLIT_SIZE)\n",
    "    test_len = int(len(dataset) - train_len)\n",
    "    shuffled_set = random.sample(dataset, len(dataset))\n",
    "    train_set = dataset[0:train_len]\n",
    "    test_set = dataset[-test_len:]\n",
    "       \n",
    "    for dataimage in train_set:\n",
    "        temp_train_set = SOURCE + dataimage\n",
    "        final_train_set = TRAINING + dataimage\n",
    "        copyfile(temp_train_set, final_train_set)\n",
    "    \n",
    "    for dataimage in test_set:\n",
    "        temp_test_set = SOURCE + dataimage\n",
    "        final_test_set = TESTING + dataimage\n",
    "        copyfile(temp_test_set, final_test_set)\n",
    "        \n",
    "        \n",
    "YES_SOURCE_DIR = \"Faceimage/test/augmented data/yesreal/\"\n",
    "TRAINING_YES_DIR = \"Faceimage/test/augmented data/training/yes/\"\n",
    "TESTING_YES_DIR = \"Faceimage/test/augmented data/testing/yes/\"\n",
    "NO_SOURCE_DIR = \"Faceimage/test/augmented data/noreal/\"\n",
    "TRAINING_NO_DIR = \"Faceimage/test/augmented data/training/no/\"\n",
    "TESTING_NO_DIR = \"Faceimage/test/augmented data/testing/no/\"\n",
    "YES_SOURCE_DIR2 = \"Bodyimage/test/augmented data/yesreal/\"\n",
    "TRAINING_YES_DIR2 = \"Bodyimage/test/augmented data/training/yes/\"\n",
    "TESTING_YES_DIR2 = \"Bodyimage/test/augmented data/testing/yes/\"\n",
    "NO_SOURCE_DIR2 = \"Bodyimage/test/augmented data/noreal/\"\n",
    "TRAINING_NO_DIR2 = \"Bodyimage/test/augmented data/training/no/\"\n",
    "TESTING_NO_DIR2 = \"Bodyimage/test/augmented data/testing/no/\"\n",
    "split_size = .8\n",
    "split_data(YES_SOURCE_DIR, TRAINING_YES_DIR, TESTING_YES_DIR, split_size)\n",
    "split_data(NO_SOURCE_DIR, TRAINING_NO_DIR, TESTING_NO_DIR, split_size)\n",
    "split_data(YES_SOURCE_DIR2, TRAINING_YES_DIR2, TESTING_YES_DIR2, split_size)\n",
    "split_data(NO_SOURCE_DIR2, TRAINING_NO_DIR2, TESTING_NO_DIR2, split_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(100, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(100, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "\n",
    "model2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(100, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(100, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "'''\n",
    "model = load_model('face_model.h5')\n",
    "model2 = load_model('body_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTRAINING_DIR = \"Faceimage/test/augmented data/training\"\\ntrain_datagen = ImageDataGenerator(rescale=1.0/255,\\n                                   rotation_range=40,\\n                                   width_shift_range=0.2,\\n                                   height_shift_range=0.2,\\n                                   shear_range=0.2,\\n                                   zoom_range=0.2,\\n                                   horizontal_flip=True,\\n                                   fill_mode=\\'nearest\\')\\n\\ntrain_generator = train_datagen.flow_from_directory(TRAINING_DIR, \\n                                                    batch_size=10, \\n                                                    target_size=(150, 150))\\nVALIDATION_DIR = \"Faceimage/test/augmented data/testing\"\\nvalidation_datagen = ImageDataGenerator(rescale=1.0/255)\\n\\nvalidation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, \\n                                                         batch_size=10, \\n                                                         target_size=(150, 150))\\ncheckpoint = ModelCheckpoint(\\'model-{epoch:03d}.model\\',monitor=\\'val_loss\\',verbose=0,save_best_only=True,mode=\\'auto\\')\\n\\n#######\\n\\nTRAINING_DIR2 = \"Bodyimage/test/augmented data/training\"\\ntrain_datagen2 = ImageDataGenerator(rescale=1.0/255,\\n                                   rotation_range=40,\\n                                   width_shift_range=0.2,\\n                                   height_shift_range=0.2,\\n                                   shear_range=0.2,\\n                                   zoom_range=0.2,\\n                                   horizontal_flip=True,\\n                                   fill_mode=\\'nearest\\')\\n\\ntrain_generator2 = train_datagen2.flow_from_directory(TRAINING_DIR2, \\n                                                    batch_size=10, \\n                                                    target_size=(150, 150))\\nVALIDATION_DIR2 = \"Bodyimage/test/augmented data/testing\"\\nvalidation_datagen2 = ImageDataGenerator(rescale=1.0/255)\\n\\nvalidation_generator2 = validation_datagen2.flow_from_directory(VALIDATION_DIR2, \\n                                                         batch_size=10, \\n                                                         target_size=(150, 150))\\ncheckpoint2 = ModelCheckpoint(\\'model2-{epoch:03d}.model2\\',monitor=\\'val_loss\\',verbose=0,save_best_only=True,mode=\\'auto\\')\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#학습된 모델을 load_model로 불러올 시 건너뛰세요\n",
    "'''\n",
    "TRAINING_DIR = \"Faceimage/test/augmented data/training\"\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR, \n",
    "                                                    batch_size=10, \n",
    "                                                    target_size=(150, 150))\n",
    "VALIDATION_DIR = \"Faceimage/test/augmented data/testing\"\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, \n",
    "                                                         batch_size=10, \n",
    "                                                         target_size=(150, 150))\n",
    "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
    "\n",
    "#######\n",
    "\n",
    "TRAINING_DIR2 = \"Bodyimage/test/augmented data/training\"\n",
    "train_datagen2 = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator2 = train_datagen2.flow_from_directory(TRAINING_DIR2, \n",
    "                                                    batch_size=10, \n",
    "                                                    target_size=(150, 150))\n",
    "VALIDATION_DIR2 = \"Bodyimage/test/augmented data/testing\"\n",
    "validation_datagen2 = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "validation_generator2 = validation_datagen2.flow_from_directory(VALIDATION_DIR2, \n",
    "                                                         batch_size=10, \n",
    "                                                         target_size=(150, 150))\n",
    "checkpoint2 = ModelCheckpoint('model2-{epoch:03d}.model2',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfacelearning = model.fit(train_generator,\\n                              epochs=1,\\n                              validation_data=validation_generator,\\n                              callbacks=[checkpoint])\\n\\nbodylearning = model2.fit(train_generator2,\\n                              epochs=1,\\n                              validation_data=validation_generator2,\\n                              callbacks=[checkpoint2])\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#학습된 모델을 load_model로 불러올 시 건너뛰세요\n",
    "'''\n",
    "facelearning = model.fit(train_generator,\n",
    "                              epochs=1,\n",
    "                              validation_data=validation_generator,\n",
    "                              callbacks=[checkpoint])\n",
    "\n",
    "bodylearning = model2.fit(train_generator2,\n",
    "                              epochs=1,\n",
    "                              validation_data=validation_generator2,\n",
    "                              callbacks=[checkpoint2])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('face_model.h5')\n",
    "#model2.save('body_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_dict={0:'',1:'Face'}\n",
    "labels2_dict={0:'',1:'Body'}\n",
    "color_dict={0:(0,255,0),1:(0,255,0)}\n",
    "color2_dict={0:(0,0,255),1:(0,0,255)}\n",
    "\n",
    "size = 4\n",
    "REC = cv2.VideoCapture('Lagos flood today.mp4') #영상 변경하는 곳\n",
    "\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "classifier2 = cv2.CascadeClassifier('haarcascade_fullbody.xml')\n",
    "\n",
    "while True:\n",
    "    (rval, im) = REC.read()\n",
    "\n",
    "    # 읽어들이는 이미지, 영상 크기 조정\n",
    "    mini = cv2.resize(im, (im.shape[1] // size, im.shape[0] // size))\n",
    "\n",
    "    faces = classifier.detectMultiScale(mini)\n",
    "    bodies = classifier2.detectMultiScale(mini)\n",
    "\n",
    "    # 포착된 사람에 테두리 표시\n",
    "    for f in faces:\n",
    "        (x, y, w, h) = [v * size for v in f] \n",
    "        face_img = im[y:y+h, x:x+w]\n",
    "        resized=cv2.resize(face_img,(150,150))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,150,150,3))\n",
    "        reshaped = np.vstack([reshaped])\n",
    "        result=model.predict(reshaped)\n",
    "        #print(result)\n",
    "        \n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "      \n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),color_dict[label],2)\n",
    "        cv2.rectangle(im,(x,y-40),(x+w,y),color_dict[label],-1)\n",
    "        cv2.putText(im, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "\n",
    "    for f in bodies:\n",
    "        (x, y, w, h) = [v * size for v in f]\n",
    "        body_img = im[y:y+h, x:x+w]\n",
    "        resized=cv2.resize(body_img,(150,150))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,150,150,3))\n",
    "        reshaped = np.vstack([reshaped])\n",
    "        result=model2.predict(reshaped)\n",
    "        #print(result)\n",
    "        \n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "      \n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),color2_dict[label],2)\n",
    "        cv2.rectangle(im,(x,y-40),(x+w,y),color2_dict[label],-1)\n",
    "        cv2.putText(im, labels2_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "        \n",
    "\n",
    "    cv2.imshow('LIVE',   im)\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "REC.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "4699278fd0f83fb5dc0252269675c6b57e3b05e5a9c47b017c2a35f6d0d8595e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
